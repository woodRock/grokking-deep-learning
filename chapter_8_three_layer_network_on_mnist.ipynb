{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUOn60qU/or2wQSB+OUwjc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/grokking-deep-learning/blob/main/chapter_8_three_layer_network_on_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 8 | Learning signal and ignoring noise"
      ],
      "metadata": {
        "id": "HwvVQ6mG_yW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Create the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "images, labels = (X_train[0:1000]).reshape(1000,28*28) / 255, y_train[0:1000]\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test ),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "# Freeze the seed for reproducability.\n",
        "np.random.seed(1)\n",
        "\n",
        "# Activation function\n",
        "relu = lambda x: (x >= 0) * x\n",
        "relu2deriv = lambda x: x >= 0\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.005\n",
        "iterations = 300\n",
        "hidden_size = 100\n",
        "pixels_per_image = 784\n",
        "num_labels = 10\n",
        "\n",
        "# Intitialize the weights.\n",
        "weights_0_1 = 0.2 * np.random.random((pixels_per_image, hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
        "\n",
        "# Training loop\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        input, target = images[i:i+1], labels[i:i+1]\n",
        "\n",
        "        # Forward pass\n",
        "        layer_0 = input\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "        prediction = layer_2\n",
        "\n",
        "        error += np.sum((target - prediction) ** 2)\n",
        "        correct_cnt += int(np.argmax(prediction) == np.argmax(target))\n",
        "\n",
        "        # Back propgation\n",
        "        layer_2_delta = (target - prediction)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "        # Update weights\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if (j % 10 == 0 or j == iterations -1):\n",
        "        test_error, test_correct_cnt = (0.0, 0)\n",
        "\n",
        "        for i in range(len(test_images)):\n",
        "            input, target = test_images[i:i+1], test_labels[i:i+1]\n",
        "\n",
        "            # Forward pass\n",
        "            layer_0 = input\n",
        "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "            layer_2 = np.dot(layer_1, weights_1_2)\n",
        "            prediction = layer_2\n",
        "\n",
        "            test_error += np.sum((target - prediction) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(prediction) == np.argmax(target))\n",
        "        message=f\"I:{j} Training Error: {error/float(len(images)):.4f} Correct: {correct_cnt/float(len(images))} \\t Test Error: {test_error/float(len(test_images)):.4f} Correct: {test_correct_cnt/float(len(test_images))}\"\n",
        "        print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDA6u6HlI_26",
        "outputId": "d40d03fd-e501-44b1-9c91-c7243ef413f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I:0 Training Error: 0.6633 Correct: 0.642 \t Test Error: 0.5853 Correct: 0.6926\n",
            "I:10 Training Error: 0.2724 Correct: 0.921 \t Test Error: 0.3983 Correct: 0.8369\n",
            "I:20 Training Error: 0.2231 Correct: 0.949 \t Test Error: 0.3918 Correct: 0.837\n",
            "I:30 Training Error: 0.2000 Correct: 0.964 \t Test Error: 0.4017 Correct: 0.8289\n",
            "I:40 Training Error: 0.1839 Correct: 0.973 \t Test Error: 0.4127 Correct: 0.8186\n",
            "I:50 Training Error: 0.1719 Correct: 0.976 \t Test Error: 0.4237 Correct: 0.8106\n",
            "I:60 Training Error: 0.1628 Correct: 0.981 \t Test Error: 0.4348 Correct: 0.803\n",
            "I:70 Training Error: 0.1559 Correct: 0.982 \t Test Error: 0.4456 Correct: 0.7958\n",
            "I:80 Training Error: 0.1504 Correct: 0.988 \t Test Error: 0.4564 Correct: 0.7907\n",
            "I:90 Training Error: 0.1460 Correct: 0.988 \t Test Error: 0.4667 Correct: 0.7863\n",
            "I:100 Training Error: 0.1426 Correct: 0.99 \t Test Error: 0.4765 Correct: 0.782\n",
            "I:110 Training Error: 0.1400 Correct: 0.991 \t Test Error: 0.4854 Correct: 0.7781\n",
            "I:120 Training Error: 0.1381 Correct: 0.991 \t Test Error: 0.4937 Correct: 0.7719\n",
            "I:130 Training Error: 0.1366 Correct: 0.991 \t Test Error: 0.5016 Correct: 0.7669\n",
            "I:140 Training Error: 0.1353 Correct: 0.992 \t Test Error: 0.5095 Correct: 0.763\n",
            "I:150 Training Error: 0.1342 Correct: 0.992 \t Test Error: 0.5174 Correct: 0.7588\n",
            "I:160 Training Error: 0.1333 Correct: 0.993 \t Test Error: 0.5249 Correct: 0.7562\n",
            "I:170 Training Error: 0.1323 Correct: 0.993 \t Test Error: 0.5320 Correct: 0.7522\n",
            "I:180 Training Error: 0.1311 Correct: 0.994 \t Test Error: 0.5386 Correct: 0.7482\n",
            "I:190 Training Error: 0.1300 Correct: 0.995 \t Test Error: 0.5447 Correct: 0.7432\n",
            "I:200 Training Error: 0.1288 Correct: 0.995 \t Test Error: 0.5506 Correct: 0.7407\n",
            "I:210 Training Error: 0.1276 Correct: 0.996 \t Test Error: 0.5561 Correct: 0.7359\n",
            "I:220 Training Error: 0.1262 Correct: 0.996 \t Test Error: 0.5612 Correct: 0.734\n",
            "I:230 Training Error: 0.1248 Correct: 0.998 \t Test Error: 0.5659 Correct: 0.7304\n",
            "I:240 Training Error: 0.1234 Correct: 0.998 \t Test Error: 0.5702 Correct: 0.7284\n",
            "I:250 Training Error: 0.1220 Correct: 0.998 \t Test Error: 0.5741 Correct: 0.7259\n",
            "I:260 Training Error: 0.1207 Correct: 0.998 \t Test Error: 0.5781 Correct: 0.7242\n",
            "I:270 Training Error: 0.1194 Correct: 0.998 \t Test Error: 0.5818 Correct: 0.723\n",
            "I:280 Training Error: 0.1181 Correct: 0.998 \t Test Error: 0.5852 Correct: 0.7222\n",
            "I:290 Training Error: 0.1169 Correct: 0.998 \t Test Error: 0.5884 Correct: 0.721\n",
            "I:299 Training Error: 0.1158 Correct: 0.999 \t Test Error: 0.5911 Correct: 0.7185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout (Srivastava 2014)\n",
        "\n",
        "References:\n",
        "1. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958."
      ],
      "metadata": {
        "id": "FKDHmA5TGuyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngdLdVsl6WXR",
        "outputId": "4238777b-e4fc-4fcf-a7ce-b8ace895b25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I:0 Training Error: 0.8912 Correct: 0.413 \t Test Error: 0.6414 Correct: 0.6333\n",
            "I:10 Training Error: 0.4721 Correct: 0.764 \t Test Error: 0.4585 Correct: 0.787\n",
            "I:20 Training Error: 0.4309 Correct: 0.809 \t Test Error: 0.4156 Correct: 0.8133\n",
            "I:30 Training Error: 0.4157 Correct: 0.811 \t Test Error: 0.4213 Correct: 0.8114\n",
            "I:40 Training Error: 0.4132 Correct: 0.827 \t Test Error: 0.4200 Correct: 0.8112\n",
            "I:50 Training Error: 0.3922 Correct: 0.836 \t Test Error: 0.4099 Correct: 0.8133\n",
            "I:60 Training Error: 0.4025 Correct: 0.836 \t Test Error: 0.4127 Correct: 0.8236\n",
            "I:70 Training Error: 0.3833 Correct: 0.857 \t Test Error: 0.4121 Correct: 0.8033\n",
            "I:80 Training Error: 0.3867 Correct: 0.854 \t Test Error: 0.4107 Correct: 0.8054\n",
            "I:90 Training Error: 0.3769 Correct: 0.868 \t Test Error: 0.4111 Correct: 0.8144\n",
            "I:100 Training Error: 0.3697 Correct: 0.864 \t Test Error: 0.4112 Correct: 0.7903\n",
            "I:110 Training Error: 0.3717 Correct: 0.868 \t Test Error: 0.4110 Correct: 0.8003\n",
            "I:120 Training Error: 0.3531 Correct: 0.857 \t Test Error: 0.4028 Correct: 0.8046\n",
            "I:130 Training Error: 0.3524 Correct: 0.867 \t Test Error: 0.4088 Correct: 0.8091\n",
            "I:140 Training Error: 0.3556 Correct: 0.885 \t Test Error: 0.4058 Correct: 0.8083\n",
            "I:150 Training Error: 0.3425 Correct: 0.883 \t Test Error: 0.4041 Correct: 0.8107\n",
            "I:160 Training Error: 0.3610 Correct: 0.876 \t Test Error: 0.3997 Correct: 0.8146\n",
            "I:170 Training Error: 0.3449 Correct: 0.889 \t Test Error: 0.4043 Correct: 0.8074\n",
            "I:180 Training Error: 0.3331 Correct: 0.892 \t Test Error: 0.3994 Correct: 0.807\n",
            "I:190 Training Error: 0.3353 Correct: 0.898 \t Test Error: 0.4075 Correct: 0.8066\n",
            "I:200 Training Error: 0.3477 Correct: 0.893 \t Test Error: 0.4053 Correct: 0.8036\n",
            "I:210 Training Error: 0.3369 Correct: 0.894 \t Test Error: 0.4051 Correct: 0.8034\n",
            "I:220 Training Error: 0.3256 Correct: 0.896 \t Test Error: 0.4025 Correct: 0.8067\n",
            "I:230 Training Error: 0.3216 Correct: 0.894 \t Test Error: 0.4044 Correct: 0.8091\n",
            "I:240 Training Error: 0.3320 Correct: 0.898 \t Test Error: 0.4150 Correct: 0.8091\n",
            "I:250 Training Error: 0.3203 Correct: 0.899 \t Test Error: 0.3952 Correct: 0.8182\n",
            "I:260 Training Error: 0.3218 Correct: 0.899 \t Test Error: 0.3903 Correct: 0.8204\n",
            "I:270 Training Error: 0.3126 Correct: 0.906 \t Test Error: 0.3821 Correct: 0.8194\n",
            "I:280 Training Error: 0.3172 Correct: 0.9 \t Test Error: 0.3964 Correct: 0.8208\n",
            "I:290 Training Error: 0.3016 Correct: 0.908 \t Test Error: 0.3999 Correct: 0.8181\n",
            "I:299 Training Error: 0.3012 Correct: 0.916 \t Test Error: 0.3931 Correct: 0.8229\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Create the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "images, labels = (X_train[0:1000]).reshape(1000,28*28) / 255, y_train[0:1000]\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test ),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "# Freeze the seed for reproducability.\n",
        "np.random.seed(1)\n",
        "\n",
        "# Activation function\n",
        "relu = lambda x: (x >= 0) * x\n",
        "relu2deriv = lambda x: x >= 0\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.005\n",
        "iterations = 300\n",
        "hidden_size = 100\n",
        "pixels_per_image = 784\n",
        "num_labels = 10\n",
        "\n",
        "# Intitialize the weights.\n",
        "weights_0_1 = 0.2 * np.random.random((pixels_per_image, hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
        "\n",
        "# Training loop\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        input, target = images[i:i+1], labels[i:i+1]\n",
        "\n",
        "        # Forward pass\n",
        "        layer_0 = input\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        # Dropout\n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "        prediction = layer_2\n",
        "\n",
        "        error += np.sum((target - prediction) ** 2)\n",
        "        correct_cnt += int(np.argmax(prediction) == np.argmax(target))\n",
        "\n",
        "        # Back propgation\n",
        "        layer_2_delta = (target - prediction)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "\n",
        "        # Update weights\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if (j % 10 == 0 or j == iterations -1):\n",
        "        test_error, test_correct_cnt = (0.0, 0)\n",
        "\n",
        "        for i in range(len(test_images)):\n",
        "            input, target = test_images[i:i+1], test_labels[i:i+1]\n",
        "\n",
        "            # Forward pass\n",
        "            layer_0 = input\n",
        "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "            layer_2 = np.dot(layer_1, weights_1_2)\n",
        "            prediction = layer_2\n",
        "\n",
        "            test_error += np.sum((target - prediction) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(prediction) == np.argmax(target))\n",
        "        message=f\"I:{j} Training Error: {error/float(len(images)):.4f} Correct: {correct_cnt/float(len(images))} \\t Test Error: {test_error/float(len(test_images)):.4f} Correct: {test_correct_cnt/float(len(test_images))}\"\n",
        "        print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch gradient descent"
      ],
      "metadata": {
        "id": "iKdBezHWJa32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "images, labels = (X_train[0:1000]).reshape(1000,28*28) / 255, y_train[0:1000]\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test ),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "# Freeze the seed for reproducability.\n",
        "np.random.seed(1)\n",
        "\n",
        "# Activation function\n",
        "def relu(x):\n",
        "    return (x >= 0) * x # returns x if x > 0\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output >= 0 # returns 1 for input > 0\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "alpha, iterations = (0.1, 1_000)\n",
        "pixels_per_image, num_labels, hidden_size = (784, 10, 100)\n",
        "\n",
        "# Initialize the network.\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
        "\n",
        "# Training loop\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size),((i+1)*batch_size))\n",
        "        input, target = images[batch_start:batch_end], labels[batch_start:batch_end]\n",
        "\n",
        "        # Forward pass\n",
        "        layer_0 = input\n",
        "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "        # Dropout\n",
        "        dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = np.dot(layer_1,weights_1_2)\n",
        "        prediction = layer_2\n",
        "\n",
        "        error += np.sum((target - layer_2) ** 2)\n",
        "        for k in range(batch_size):\n",
        "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
        "\n",
        "        # Back propagation\n",
        "        layer_2_delta = (target-prediction)/batch_size\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)* relu2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "\n",
        "        # Update weights\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if(j % 10 == 0 or j == iterations - 1):\n",
        "        test_error = 0.0\n",
        "        test_correct_cnt = 0\n",
        "\n",
        "        for i in range(len(test_images)):\n",
        "            layer_0 = test_images[i:i+1]\n",
        "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "            layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "                         \"I:\" + str(j) + \\\n",
        "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
        "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
        "                         \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "                         \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHoyg7LEJaed",
        "outputId": "ccf76d47-3cbd-40a9-fb8f-1b5d03014940"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I:0 Test-Err:0.815 Test-Acc:0.3832 Train-Err:1.272 Train-Acc:0.161\n",
            "I:10 Test-Err:0.569 Test-Acc:0.7183 Train-Err:0.591 Train-Acc:0.672\n",
            "I:20 Test-Err:0.508 Test-Acc:0.7577 Train-Err:0.530 Train-Acc:0.727\n",
            "I:30 Test-Err:0.483 Test-Acc:0.7815 Train-Err:0.497 Train-Acc:0.758\n",
            "I:40 Test-Err:0.464 Test-Acc:0.7915 Train-Err:0.486 Train-Acc:0.75\n",
            "I:50 Test-Err:0.453 Test-Acc:0.7978 Train-Err:0.462 Train-Acc:0.784\n",
            "I:60 Test-Err:0.446 Test-Acc:0.8015 Train-Err:0.445 Train-Acc:0.801\n",
            "I:70 Test-Err:0.437 Test-Acc:0.8054 Train-Err:0.444 Train-Acc:0.807\n",
            "I:80 Test-Err:0.440 Test-Acc:0.807 Train-Err:0.450 Train-Acc:0.803\n",
            "I:90 Test-Err:0.437 Test-Acc:0.8059 Train-Err:0.444 Train-Acc:0.798\n",
            "I:100 Test-Err:0.437 Test-Acc:0.8029 Train-Err:0.436 Train-Acc:0.805\n",
            "I:110 Test-Err:0.431 Test-Acc:0.8024 Train-Err:0.420 Train-Acc:0.818\n",
            "I:120 Test-Err:0.433 Test-Acc:0.8006 Train-Err:0.419 Train-Acc:0.824\n",
            "I:130 Test-Err:0.432 Test-Acc:0.8003 Train-Err:0.424 Train-Acc:0.826\n",
            "I:140 Test-Err:0.440 Test-Acc:0.7998 Train-Err:0.430 Train-Acc:0.832\n",
            "I:150 Test-Err:0.437 Test-Acc:0.7967 Train-Err:0.410 Train-Acc:0.818\n",
            "I:160 Test-Err:0.435 Test-Acc:0.8052 Train-Err:0.422 Train-Acc:0.811\n",
            "I:170 Test-Err:0.436 Test-Acc:0.7953 Train-Err:0.412 Train-Acc:0.846\n",
            "I:180 Test-Err:0.432 Test-Acc:0.8049 Train-Err:0.405 Train-Acc:0.842\n",
            "I:190 Test-Err:0.430 Test-Acc:0.8013 Train-Err:0.404 Train-Acc:0.84\n",
            "I:200 Test-Err:0.430 Test-Acc:0.8089 Train-Err:0.415 Train-Acc:0.844\n",
            "I:210 Test-Err:0.427 Test-Acc:0.801 Train-Err:0.398 Train-Acc:0.844\n",
            "I:220 Test-Err:0.426 Test-Acc:0.8064 Train-Err:0.392 Train-Acc:0.841\n",
            "I:230 Test-Err:0.424 Test-Acc:0.8088 Train-Err:0.389 Train-Acc:0.849\n",
            "I:240 Test-Err:0.425 Test-Acc:0.8114 Train-Err:0.392 Train-Acc:0.85\n",
            "I:250 Test-Err:0.424 Test-Acc:0.8074 Train-Err:0.385 Train-Acc:0.851\n",
            "I:260 Test-Err:0.423 Test-Acc:0.8129 Train-Err:0.390 Train-Acc:0.853\n",
            "I:270 Test-Err:0.421 Test-Acc:0.8071 Train-Err:0.378 Train-Acc:0.866\n",
            "I:280 Test-Err:0.421 Test-Acc:0.8124 Train-Err:0.393 Train-Acc:0.856\n",
            "I:290 Test-Err:0.418 Test-Acc:0.806 Train-Err:0.375 Train-Acc:0.862\n",
            "I:300 Test-Err:0.420 Test-Acc:0.8119 Train-Err:0.380 Train-Acc:0.86\n",
            "I:310 Test-Err:0.420 Test-Acc:0.809 Train-Err:0.377 Train-Acc:0.858\n",
            "I:320 Test-Err:0.420 Test-Acc:0.8106 Train-Err:0.376 Train-Acc:0.854\n",
            "I:330 Test-Err:0.416 Test-Acc:0.8107 Train-Err:0.382 Train-Acc:0.861\n",
            "I:340 Test-Err:0.417 Test-Acc:0.8126 Train-Err:0.385 Train-Acc:0.848\n",
            "I:350 Test-Err:0.421 Test-Acc:0.8064 Train-Err:0.374 Train-Acc:0.865\n",
            "I:360 Test-Err:0.415 Test-Acc:0.8105 Train-Err:0.371 Train-Acc:0.853\n",
            "I:370 Test-Err:0.416 Test-Acc:0.8098 Train-Err:0.368 Train-Acc:0.85\n",
            "I:380 Test-Err:0.415 Test-Acc:0.8134 Train-Err:0.366 Train-Acc:0.858\n",
            "I:390 Test-Err:0.413 Test-Acc:0.812 Train-Err:0.354 Train-Acc:0.87\n",
            "I:400 Test-Err:0.411 Test-Acc:0.8094 Train-Err:0.364 Train-Acc:0.87\n",
            "I:410 Test-Err:0.410 Test-Acc:0.8128 Train-Err:0.360 Train-Acc:0.874\n",
            "I:420 Test-Err:0.410 Test-Acc:0.8124 Train-Err:0.362 Train-Acc:0.871\n",
            "I:430 Test-Err:0.412 Test-Acc:0.8159 Train-Err:0.369 Train-Acc:0.855\n",
            "I:440 Test-Err:0.408 Test-Acc:0.8176 Train-Err:0.368 Train-Acc:0.872\n",
            "I:450 Test-Err:0.412 Test-Acc:0.8129 Train-Err:0.351 Train-Acc:0.883\n",
            "I:460 Test-Err:0.408 Test-Acc:0.8189 Train-Err:0.370 Train-Acc:0.866\n",
            "I:470 Test-Err:0.404 Test-Acc:0.8177 Train-Err:0.367 Train-Acc:0.859\n",
            "I:480 Test-Err:0.410 Test-Acc:0.8176 Train-Err:0.363 Train-Acc:0.863\n",
            "I:490 Test-Err:0.406 Test-Acc:0.8119 Train-Err:0.358 Train-Acc:0.875\n",
            "I:500 Test-Err:0.403 Test-Acc:0.8199 Train-Err:0.359 Train-Acc:0.873\n",
            "I:510 Test-Err:0.402 Test-Acc:0.8181 Train-Err:0.345 Train-Acc:0.878\n",
            "I:520 Test-Err:0.406 Test-Acc:0.815 Train-Err:0.351 Train-Acc:0.866\n",
            "I:530 Test-Err:0.400 Test-Acc:0.8181 Train-Err:0.345 Train-Acc:0.884\n",
            "I:540 Test-Err:0.402 Test-Acc:0.8178 Train-Err:0.352 Train-Acc:0.883\n",
            "I:550 Test-Err:0.402 Test-Acc:0.8193 Train-Err:0.342 Train-Acc:0.882\n",
            "I:560 Test-Err:0.401 Test-Acc:0.8192 Train-Err:0.341 Train-Acc:0.879\n",
            "I:570 Test-Err:0.402 Test-Acc:0.819 Train-Err:0.348 Train-Acc:0.879\n",
            "I:580 Test-Err:0.404 Test-Acc:0.8197 Train-Err:0.350 Train-Acc:0.878\n",
            "I:590 Test-Err:0.400 Test-Acc:0.8184 Train-Err:0.339 Train-Acc:0.885\n",
            "I:600 Test-Err:0.400 Test-Acc:0.8199 Train-Err:0.348 Train-Acc:0.876\n",
            "I:610 Test-Err:0.399 Test-Acc:0.8187 Train-Err:0.346 Train-Acc:0.882\n",
            "I:620 Test-Err:0.402 Test-Acc:0.8186 Train-Err:0.343 Train-Acc:0.879\n",
            "I:630 Test-Err:0.398 Test-Acc:0.8183 Train-Err:0.337 Train-Acc:0.881\n",
            "I:640 Test-Err:0.396 Test-Acc:0.8165 Train-Err:0.338 Train-Acc:0.887\n",
            "I:650 Test-Err:0.398 Test-Acc:0.8198 Train-Err:0.332 Train-Acc:0.9\n",
            "I:660 Test-Err:0.398 Test-Acc:0.8158 Train-Err:0.337 Train-Acc:0.881\n",
            "I:670 Test-Err:0.400 Test-Acc:0.8189 Train-Err:0.343 Train-Acc:0.881\n",
            "I:680 Test-Err:0.399 Test-Acc:0.8167 Train-Err:0.326 Train-Acc:0.893\n",
            "I:690 Test-Err:0.397 Test-Acc:0.8207 Train-Err:0.335 Train-Acc:0.891\n",
            "I:700 Test-Err:0.398 Test-Acc:0.8204 Train-Err:0.327 Train-Acc:0.888\n",
            "I:710 Test-Err:0.396 Test-Acc:0.8169 Train-Err:0.337 Train-Acc:0.883\n",
            "I:720 Test-Err:0.397 Test-Acc:0.8175 Train-Err:0.330 Train-Acc:0.891\n",
            "I:730 Test-Err:0.394 Test-Acc:0.8164 Train-Err:0.327 Train-Acc:0.894\n",
            "I:740 Test-Err:0.395 Test-Acc:0.8186 Train-Err:0.327 Train-Acc:0.89\n",
            "I:750 Test-Err:0.395 Test-Acc:0.8156 Train-Err:0.321 Train-Acc:0.885\n",
            "I:760 Test-Err:0.394 Test-Acc:0.8187 Train-Err:0.328 Train-Acc:0.884\n",
            "I:770 Test-Err:0.395 Test-Acc:0.8148 Train-Err:0.332 Train-Acc:0.89\n",
            "I:780 Test-Err:0.394 Test-Acc:0.817 Train-Err:0.326 Train-Acc:0.904\n",
            "I:790 Test-Err:0.394 Test-Acc:0.8183 Train-Err:0.326 Train-Acc:0.895\n",
            "I:800 Test-Err:0.392 Test-Acc:0.8159 Train-Err:0.330 Train-Acc:0.891\n",
            "I:810 Test-Err:0.391 Test-Acc:0.8152 Train-Err:0.321 Train-Acc:0.888\n",
            "I:820 Test-Err:0.390 Test-Acc:0.8186 Train-Err:0.319 Train-Acc:0.903\n",
            "I:830 Test-Err:0.388 Test-Acc:0.8179 Train-Err:0.327 Train-Acc:0.903\n",
            "I:840 Test-Err:0.389 Test-Acc:0.8162 Train-Err:0.318 Train-Acc:0.893\n",
            "I:850 Test-Err:0.389 Test-Acc:0.8158 Train-Err:0.327 Train-Acc:0.889\n",
            "I:860 Test-Err:0.390 Test-Acc:0.818 Train-Err:0.313 Train-Acc:0.897\n",
            "I:870 Test-Err:0.391 Test-Acc:0.8184 Train-Err:0.326 Train-Acc:0.887\n",
            "I:880 Test-Err:0.394 Test-Acc:0.8142 Train-Err:0.332 Train-Acc:0.892\n",
            "I:890 Test-Err:0.390 Test-Acc:0.811 Train-Err:0.322 Train-Acc:0.898\n",
            "I:900 Test-Err:0.390 Test-Acc:0.8098 Train-Err:0.314 Train-Acc:0.901\n",
            "I:910 Test-Err:0.393 Test-Acc:0.8171 Train-Err:0.322 Train-Acc:0.892\n",
            "I:920 Test-Err:0.390 Test-Acc:0.8133 Train-Err:0.309 Train-Acc:0.897\n",
            "I:930 Test-Err:0.391 Test-Acc:0.8134 Train-Err:0.316 Train-Acc:0.901\n",
            "I:940 Test-Err:0.389 Test-Acc:0.8141 Train-Err:0.319 Train-Acc:0.907\n",
            "I:950 Test-Err:0.392 Test-Acc:0.8105 Train-Err:0.311 Train-Acc:0.906\n",
            "I:960 Test-Err:0.388 Test-Acc:0.8158 Train-Err:0.317 Train-Acc:0.903\n",
            "I:970 Test-Err:0.392 Test-Acc:0.8148 Train-Err:0.318 Train-Acc:0.896\n",
            "I:980 Test-Err:0.387 Test-Acc:0.8146 Train-Err:0.308 Train-Acc:0.902\n",
            "I:990 Test-Err:0.387 Test-Acc:0.8157 Train-Err:0.317 Train-Acc:0.897\n",
            "I:999 Test-Err:0.388 Test-Acc:0.8113 Train-Err:0.317 Train-Acc:0.898"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.randint(2, size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6-yPN2EZ7Nf",
        "outputId": "72f9d58d-13b7-42e7-c83c-657cd616528b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}